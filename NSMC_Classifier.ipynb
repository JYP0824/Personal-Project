{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f22d68ae-d825-47e4-abe0-49ff65ffb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d52550-bf86-4af5-a221-cea33af47adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 74997 entries, 59770 to 96244\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        74997 non-null  int64 \n",
      " 1   document  74997 non-null  object\n",
      " 2   label     74997 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train = '/home/ines/JYP/Dataset/ratings_train.txt'\n",
    "test = '/home/ines/JYP/Dataset/ratings_test.txt'\n",
    "\n",
    "tra = pd.read_csv(train, sep='\\t')\n",
    "tes = pd.read_csv(test, sep='\\t')\n",
    "\n",
    "tr = tra.sample(frac=0.5, random_state=42)\n",
    "te = tes.sample(frac=0.5, random_state=42)\n",
    "\n",
    "tr.dropna(inplace=True)\n",
    "te.dropna(inplace=True)\n",
    "tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacf828f-5df1-431a-a504-355ac7d3492a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "tr_doc = tr['document']\n",
    "tr_lb = tr['label']\n",
    "te_doc = te['document']\n",
    "te_lb = te['label']\n",
    "\n",
    "max_len = max(len(sent) for sent in tr_doc)\n",
    "print(max_len)\n",
    "\n",
    "train_doc, val_doc, train_lb, val_lb = train_test_split(tr_doc, tr_lb, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8d517a-dbc5-4549-ad1f-71b5aaf5c265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased', num_labels=2)\n",
    "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f245c86-31c8-45e7-be0f-6394ee754379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9dc9cb-487e-45ce-bbf0-f7b2ba192fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_tok(doc):\n",
    "    tokenized = []\n",
    "    mask = []\n",
    "    for sent in doc:\n",
    "        tok_sen = tokenizer(sent, max_length=146, padding='max_length', truncation=True)\n",
    "        tok_id = tok_sen['input_ids']\n",
    "        att_mask = tok_sen['attention_mask']\n",
    "        tokenized.append(tok_id)\n",
    "        mask.append(att_mask)\n",
    "    return tokenized, mask\n",
    "\n",
    "\n",
    "tr_tok, tr_mask = pre_tok(train_doc)\n",
    "val_tok, val_mask = pre_tok(val_doc)\n",
    "te_tok, te_mask = pre_tok(te_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac1dcfd-f441-407d-9179-3b34ee42f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_tok_ten = torch.tensor(tr_tok)\n",
    "tr_mask_ten = torch.tensor(tr_mask)\n",
    "tr_lb = torch.tensor(list(train_lb))\n",
    "\n",
    "val_tok_ten = torch.tensor(val_tok)\n",
    "val_mask_ten = torch.tensor(val_mask)\n",
    "val_lb = torch.tensor(list(val_lb))\n",
    "\n",
    "te_tok_ten = torch.tensor(te_tok)\n",
    "te_mask_ten = torch.tensor(te_mask)\n",
    "te_lb = torch.tensor(list(te_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869c3a6f-107a-4fc6-be64-23eb1c814310",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, tok, mask, lb):\n",
    "        super(CustomDataset, self).__init__()\n",
    "\n",
    "        self.tok = tok\n",
    "        self.mask = mask\n",
    "        self.lb = lb\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lb)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.tok[idx].clone().detach(),\n",
    "            'attention_mask': self.mask[idx].clone().detach(),\n",
    "            'labels': self.lb[idx].clone().detach()\n",
    "        }\n",
    "    \n",
    "\n",
    "#batch size\n",
    "batch_size = 16\n",
    "\n",
    "tr_set = CustomDataset(tr_tok_ten, tr_mask_ten, tr_lb)\n",
    "val_set = CustomDataset(val_tok_ten, val_mask_ten, val_lb)\n",
    "te_set = CustomDataset(te_tok_ten, te_mask_ten, te_lb)\n",
    "\n",
    "tr_dl = DataLoader(tr_set, batch_size = batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_set, batch_size = batch_size, shuffle=True)\n",
    "te_dl = DataLoader(te_set, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b819138d-a632-4963-9959-5f21c9d8af81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/ines/JYP\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1541a78e-a1a1-4e8e-9d4d-72e650144f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqkrwodbs0824\u001b[0m (\u001b[33mines_\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ines/JYP/wandb/run-20240203_215602-0w3o6asj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ines_/NSMC_Classification/runs/0w3o6asj' target=\"_blank\">lucky-dawn-28</a></strong> to <a href='https://wandb.ai/ines_/NSMC_Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ines_/NSMC_Classification' target=\"_blank\">https://wandb.ai/ines_/NSMC_Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ines_/NSMC_Classification/runs/0w3o6asj' target=\"_blank\">https://wandb.ai/ines_/NSMC_Classification/runs/0w3o6asj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter\n",
    "lr = 1e-5\n",
    "epochs = 5\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, eps=1e-8)\n",
    "\n",
    "wandb.init(project='NSMC_Classification')\n",
    "wandb.run.name='Res_epoch_5'\n",
    "wandb.run.save()\n",
    "\n",
    "args = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size\n",
    "}\n",
    "wandb.config.update(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8e99dd-2967-4d67-8e50-0efcf76c17f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 - steps: 0 Tr_loss: 0.6700  Tr_accuracy: 0.5625\n",
      "epoch:1 - steps: 500 Tr_loss: 0.3678  Tr_accuracy: 0.8750\n",
      "epoch:1 - steps: 1000 Tr_loss: 0.7176  Tr_accuracy: 0.5625\n",
      "epoch:1 - steps: 1500 Tr_loss: 0.5891  Tr_accuracy: 0.6875\n",
      "epoch:1 - steps: 2000 Tr_loss: 0.2263  Tr_accuracy: 0.9375\n",
      "epoch:1 - steps: 2500 Tr_loss: 0.4548  Tr_accuracy: 0.7500\n",
      "epoch:1 - steps: 3000 Tr_loss: 0.3110  Tr_accuracy: 0.9375\n",
      "epoch:1 - steps: 3500 Tr_loss: 0.6454  Tr_accuracy: 0.6875\n",
      "epoch:1 - steps: 4000 Tr_loss: 0.2518  Tr_accuracy: 0.8750\n",
      "val_loss: 0.0237 val_acc: 0.6667\n",
      "epoch:2 - steps: 0 Tr_loss: 0.2640  Tr_accuracy: 0.9375\n",
      "epoch:2 - steps: 500 Tr_loss: 0.1974  Tr_accuracy: 0.8750\n",
      "epoch:2 - steps: 1000 Tr_loss: 0.1533  Tr_accuracy: 0.9375\n",
      "epoch:2 - steps: 1500 Tr_loss: 0.4013  Tr_accuracy: 0.8125\n",
      "epoch:2 - steps: 2000 Tr_loss: 0.3598  Tr_accuracy: 0.8750\n",
      "epoch:2 - steps: 2500 Tr_loss: 0.2872  Tr_accuracy: 0.8750\n",
      "epoch:2 - steps: 3000 Tr_loss: 0.2700  Tr_accuracy: 0.8750\n",
      "epoch:2 - steps: 3500 Tr_loss: 0.2606  Tr_accuracy: 0.8750\n",
      "epoch:2 - steps: 4000 Tr_loss: 0.4508  Tr_accuracy: 0.7500\n",
      "val_loss: 0.0226 val_acc: 0.9167\n",
      "epoch:3 - steps: 0 Tr_loss: 0.3646  Tr_accuracy: 0.8125\n",
      "epoch:3 - steps: 500 Tr_loss: 0.1774  Tr_accuracy: 0.9375\n",
      "epoch:3 - steps: 1000 Tr_loss: 0.3900  Tr_accuracy: 0.8750\n",
      "epoch:3 - steps: 1500 Tr_loss: 0.0522  Tr_accuracy: 1.0000\n",
      "epoch:3 - steps: 2000 Tr_loss: 0.2361  Tr_accuracy: 0.8750\n",
      "epoch:3 - steps: 2500 Tr_loss: 0.5095  Tr_accuracy: 0.7500\n",
      "epoch:3 - steps: 3000 Tr_loss: 0.5123  Tr_accuracy: 0.7500\n",
      "epoch:3 - steps: 3500 Tr_loss: 0.1287  Tr_accuracy: 0.9375\n",
      "epoch:3 - steps: 4000 Tr_loss: 0.1136  Tr_accuracy: 0.9375\n",
      "val_loss: 0.0224 val_acc: 0.5833\n",
      "epoch:4 - steps: 0 Tr_loss: 0.1875  Tr_accuracy: 0.8750\n",
      "epoch:4 - steps: 500 Tr_loss: 0.0928  Tr_accuracy: 1.0000\n",
      "epoch:4 - steps: 1000 Tr_loss: 0.0688  Tr_accuracy: 1.0000\n",
      "epoch:4 - steps: 1500 Tr_loss: 0.2194  Tr_accuracy: 0.8750\n",
      "epoch:4 - steps: 2000 Tr_loss: 0.1793  Tr_accuracy: 0.8750\n",
      "epoch:4 - steps: 2500 Tr_loss: 0.2330  Tr_accuracy: 0.8750\n",
      "epoch:4 - steps: 3000 Tr_loss: 0.0878  Tr_accuracy: 1.0000\n",
      "epoch:4 - steps: 3500 Tr_loss: 0.1147  Tr_accuracy: 0.9375\n",
      "epoch:4 - steps: 4000 Tr_loss: 0.2851  Tr_accuracy: 0.9375\n",
      "val_loss: 0.0257 val_acc: 0.9167\n",
      "epoch:5 - steps: 0 Tr_loss: 0.2746  Tr_accuracy: 0.8750\n",
      "epoch:5 - steps: 500 Tr_loss: 0.1310  Tr_accuracy: 0.9375\n",
      "epoch:5 - steps: 1000 Tr_loss: 0.2092  Tr_accuracy: 0.8750\n",
      "epoch:5 - steps: 1500 Tr_loss: 0.0187  Tr_accuracy: 1.0000\n",
      "epoch:5 - steps: 2000 Tr_loss: 0.0424  Tr_accuracy: 1.0000\n",
      "epoch:5 - steps: 2500 Tr_loss: 0.1385  Tr_accuracy: 0.9375\n",
      "epoch:5 - steps: 3000 Tr_loss: 0.0578  Tr_accuracy: 1.0000\n",
      "epoch:5 - steps: 3500 Tr_loss: 0.0686  Tr_accuracy: 1.0000\n",
      "epoch:5 - steps: 4000 Tr_loss: 0.2675  Tr_accuracy: 0.9375\n",
      "val_loss: 0.0252 val_acc: 0.8333\n",
      "Best accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Train & Validation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "loss = 0\n",
    "total_loss = 0\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    correct=0\n",
    "    total_sample = 0\n",
    "    \n",
    "    model.train()\n",
    "    for step, batch in enumerate(tr_dl):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        texts, attention_masks, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        texts, attention_masks, labels = texts.to(device), attention_masks.to(device), labels.to(device)\n",
    "        outputs = model(input_ids = texts, attention_mask = attention_masks, labels=labels)\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        pred = torch.argmax(torch.sigmoid(logits), dim=1)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        pred = pred.tolist()\n",
    "        labels = labels.tolist()\n",
    "        accuracy = accuracy_score(pred, labels)\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print(f\"epoch:{epoch+1} - steps: {step} Tr_loss: {loss.item():.4f}  Tr_accuracy: {accuracy:.4f}\")\n",
    "            wandb.log({\"Training Accuracy\": accuracy})\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_total_loss = 0\n",
    "        val_total_cor = 0\n",
    "        for v_step, batch in enumerate(val_dl):\n",
    "            val_texts, val_attention_masks, val_labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "            val_texts, val_attention_masks, val_labels = val_texts.to(device), val_attention_masks.to(device), val_labels.to(device)\n",
    "            val_outputs = model(input_ids = val_texts, attention_mask = val_attention_masks, labels=val_labels)\n",
    "\n",
    "            val_loss = val_outputs.loss\n",
    "            val_logits = val_outputs.logits\n",
    "            val_pred = torch.argmax(torch.sigmoid(val_logits), dim=1)\n",
    "            val_total_sample = len(val_dl.dataset)\n",
    "\n",
    "            val_total_loss += val_loss.item()\n",
    "            val_avg_loss = val_total_loss / val_total_sample\n",
    "        \n",
    "        val_pred = val_pred.tolist()\n",
    "        val_labels = val_labels.tolist()\n",
    "        val_acc = accuracy_score(val_pred, val_labels)\n",
    "        print(f\"val_loss: {val_avg_loss:.4f} val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    if accuracy >= best_acc:\n",
    "        best_acc = accuracy\n",
    "        torch.save(model.state_dict(), 'NSMC_Bert.pth')\n",
    "    \n",
    "print(f\"Best accuracy: {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e2f8edc-4baf-4fef-a298-67b9b82ce295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy on Test Data: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in te_dl:\n",
    "        te_texts, te_att_masks, te_lab = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        te_texts, te_att_masks, te_lab = te_texts.to(device), te_att_masks.to(device), te_lab.to(device)\n",
    "    \n",
    "        te_outputs = model(input_ids=te_texts, attention_mask=te_att_masks, labels=te_lab)\n",
    "        te_logits = te_outputs.logits\n",
    "        te_pred = torch.argmax(torch.sigmoid(te_logits), dim=1)\n",
    "\n",
    "te_pred = te_pred.tolist()\n",
    "te_lab = te_lab.tolist()\n",
    "accuracy = accuracy_score(te_pred, te_lab)\n",
    "print(f\"Total Accuracy on Test Data: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "jyp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
